XCMS course 2017
========================================================
author: 
date: 
autosize: true
width: 2540
height: 1429

```{r, echo = FALSE}
library(knitcitations)
cite_options(     
                  cite.style = "numeric"
            )
bib <- read.bibtex("bibliography.bib")
```


Outline (1)
========================================================

**XCMS**
- What does the data look like? Why pre-processing?
- Peak picking (xcmsSet)
- Grouping and retention time correction (group & retcor)
- Filling missing values (fillPeaks)
- Checking the results






What does the data look like? Why pre-processing?
========================================================
- 3D to 2D

<br>
This is what XCMS does:
- Peak-picking
- Group peaks across samples (+retention time alignment)
- Examine raw data for peaks that were not found in all samples

<br>
Simply to do. Difficult to do well. Impossible to do perfectly.


Peak picking
========================================================

- Two algoritms
- Finding reasonable peak width
- profparam
- prefilter
- Difference LC/GC (max for matchedfilter)
- Checking the results
- Exclude blanks

Find the files
========================================================
First we locate the files.
They need to be in an open format: 
* mzML (newest)
* mzData
* mzXML (most widely supported)
* netCDF (obsolete, last resort)

<br>

Lets make a list of the files we want to pre-process.
```{r}
files <- list.files("_data", recursive = TRUE, full.names = TRUE, pattern=".mzXML")
head(files,5)
```

<br>
Blanks interfer with peak alignment since there are so few peaks. So better remove them before starting. Same goes for compound mixtures.


Peak picking
========================================================

Now we can do peak picking. We need to load some packages first.


```{r}
suppressMessages(library(xcms)) # suppress avoids a flood of messages
suppressMessages(library(BiocParallel))
```

<br>
By dafault the newest XCMS uses all available cores.<br>
Below we are setting it to use one just because it works better for generating this presentation.

To control the number of cores you could for example do:
```{r, eval = FALSE}
suppressMessages(library(parallel))
BPPARAM  = SnowParam(detectCores()-2, progressbar = TRUE)
```

<br>
Now lets do the peak picking.<br>
There are many parameters to set that we will explain in a sec.<br>
There are a few more settings available but these are the most important.
```{r, cache=TRUE, message = FALSE}
xset <- xcmsSet(files, 
                BPPARAM  = SerialParam(),
                method = 'centWave',
                prefilter = c(3,1E3),
                ppm = 20,
                snthr = 5e3,
                profparam = list(step=0.005),
                peakwidth = c(0.05*60,0.20*60)
                )
```



Peak picking - which method?
========================================================

**matchedfilter** `r citep(bib[["Smith2006"]])`
* Original algoritm
* Developed for nominal mass instruments
* Good for low accuracy data
* Good for chromatographically noisy data (also high accuracy MS)
* Fixed width peak fitting

<br>
**centWave**  `r citep(bib[["Tautenhahn2008"]])`
* Developed for accurate mass instruments
* Handles different peak widths better
* prefilter makes it faster
* Usually the best if the data is "nice"


Peak picking - What peak picking does `r citep(bib[["Tautenhahn2008"]])`
========================================================

* First it finds *regions of interest* (ROIs). <br> Those are where there could be a peak: Stable mass for a certain time.
* Next the peak shape is evaluated.
* The peak is expanded beyond the ROI if needed.

<div align="center">
<img src="_images/centwave.png" height=1100px><br>
<i>Figure from the centWave paper</i>
</div>



Peak picking - What peak picking does `r citep(bib[["Tautenhahn2008"]])`
========================================================

<div align="center">
<img src="_images/centwave_ROI.png" height=1100px><br>
<i>Figure from the centWave paper</i>
</div>



Peak picking - Prefilter
========================================================

<br>
```{r, eval=FALSE}
prefilter = c(3,1E3)
```
<br>
Says to only consider regions where there are at least `3` scans with intensity above `1000`.

Check your peak widths to see how many scans per peak you are sure to have.



Peak picking - Peak width
========================================================

Centwave asks you to set the minimum and maxmimum peak widths you have in your data.<br>
You set it in seconds (always seconds in XCMS) and this is what we did before.
<br>

```{r, eval=FALSE}
peakwidth = c(0.05*60,0.20*60)
```

It is a vector of length 2 with the  min and max length.
<br><br>

To determine reasonable values we need to look at the raw data (you'd probably use something interactive such as MzMine (or future XCMS!)).<br>
Here is a TIC:
<br>
```{r, cache=TRUE, fig.width=18, fig.height=11}
xraw <- xcmsRaw(xset@filepaths[1])
plotEIC(xraw, mzrange=c(0, 2000), , rtrange=c(0,  12*60))
```





Peak picking - Peak width
========================================================

Lets zoom in on a peak.

```{r, cache=TRUE, fig.width=20, fig.height=14, echo=-1}
par(cex.axis=2, cex.lab=2)

plotEIC(xraw, 
        mzrange=c(84.9612-0.01, 84.9612+0.01), 
        rtrange=c(0.7*60,  0.9*60), 
        type="o", cex=3, pch=19, lwd=3
        )
```


***
<br><br><br><br><br><br><br><br><br>

* So we can see that this peak has ~15 scans and is about 7 s (~0.1 min) long.
* We could do the same looking at one of the longer peaks at the end of the run.
* If the short peak we can find is about 0.1 min I'd go for 0.05 min to be on the safe side. Also multiply what you can find for the longest by 2 to be safe.



Peak picking - Peak width
========================================================

You can also use a 2D plot to try to find short and long peaks.
Here I plotted with MzMine (remember to use the continuos/profile mode toggle otherwise it looks very wrong).
<br>
<div align="center">
<img src="_images/2D.png" height=1300px>
</div>



Peak picking - ppm
========================================================

<br>
ppm == Relative deviation in the m/z dimension

<br>
Do not trust the vendors number. Like the mileage of a car these numbers are far from true in real world scenarios.<br>
We need a range that is true also for the ends of the peaks.

<br>
What we choose before was:
```{r, eval=FALSE}
ppm = 20
```

<br>
A 2D plot is a reasonable way to look at this.



Peak picking - ppm
========================================================


<br>
<div align="center">
<img src="_images/trp_frag_2D.png" height=1300px>
</div>



Peak picking - ppm
========================================================
<br>
<div align="center">
<img src="_images/trp_frag_chrom.png" height=1300px>
</div>


Peak picking - ppm
========================================================

<br>
<div align="center">
<img src="_images/trp_frag_spec.png" height=1300px>
</div>


Peak picking - ppm
========================================================

<br>
<div align="center">
<img src="_images/trp_frag_2D_iso_zoom.png" height=1100px>
</div>

```{r}
((189.074-189.0690)/189.0690)*1e6
```



Peak picking - profparam
========================================================

<br>
First we need to clear up the confusion about the difference between *profile mode* data and the *profile matrix*.
<br>

**Profile mode:** The data is continuous in the *m/z* dimension.<br>
As opposed to centroid mode data where you have discrete (sticks) in the *m/z* dimension.

**Profile matrix:** A rt (or scan rather) Ã— *m/z* matrix of *m/z* slices.<br>
XCMS uses this for some procedures instead of the full raw data. Think of it as binned data with less *m/z* resolution.

<br>
* The profparam parameter says how fine the binning in the *Profile matrix* is going to be.
* For high dimensional data the default setting can cause problems. So setting something like this will set it to 0.005 Da slices.
* It cannot be set too low as slices will be combined as needed. Only memory usage will increase.

<br>

```{r, eval=FALSE}
profparam = list(step=0.005)
```





Peak picking - snthr
========================================================

Signal to noise ratio. It really depends on your data. And it is defined differently for centWave and matchedfilter.

For centWave I would start with:

```{r, eval=FALSE}
snthr = 5e3
```

For matchedfilter I would start with:

```{r, eval=FALSE}
snthr = 5
```
               
<br>
If low peaks that you would like to include are missing lower the value.




Grouping and retention time correction
========================================================

This step tries to group/match features between samples.<br>
**This is probably the most important step!**

It is a 3 step procedure:

1. Features are grouped according to RT. Loose parameters for matching is used.
2. The matched features are used to model RT shifts. --> retention time correction/alignment.
3. Using the corrected RTs features are matched again with stricter criteria.

<br>
There are three methods for retention time correction/alignment.

1. **LOESS:** Fits a LOESS curve between retention times. Works on the peaktable (therefore fast). The default and usually no reason to look further.
2. **Obiwarp:** Warps the raw data (and hence slow) to a reference sample. Can handle dramatic shifts. Often overfitting. Use if needed with great attention.
3. **Linear:** When all else fails.


Grouping and retention time correction - group
========================================================

```{r, cache=TRUE, message = FALSE}
xset_g <- group(xset, 
                bw = 0.2*60, 
                minfrac = 0.5, 
                minsamp = 5, 
                mzwid = 0.05, 
                max = 20, 
                sleep = 0
                )

xset_g
```



Grouping and retention time correction - group bw
========================================================
incremental: true

*TODO: density plot?*

**bw**: bandwidth (standard deviation or half width at half maximum) of gaussian smoothing kernel to apply to the peak density chromatogram. <br>

Sounds very difficult but it roughly translates to:<br>
The maximum expected RT deviation across samples.

<br>
Overlay the BPI and find the peak with the highest deviation.
<br>

<div  class="fragment" align="center">
<img src="_images/group_bw.png" height=1000px>
</div>


Grouping and retention time correction - group bw
========================================================

Here we have zoomed. Compare peak apexes.

<br>
<div align="center">
<img src="_images/group_bw_zoom.png" height=800px>
</div>


Calculate the deviation.
```{r}
4.90-4.78
```

Since there could be small peaks with larger variation than what we found we bump it up to 0.2 min.


Grouping and retention time correction - minfrac/minsamp
========================================================

```{r, eval=FALSE}
minfrac = 0.5
minsamp = 5
```

<br>

**minsamp:** minimum number of samples a peak should be found in.

**minfrac:** minimum fraction of samples a peak should be found in.

<br>
**These are used** ***per group***.

Files in different subfolders are considered different groups.<br>
The groups can be manipulated by changing:

```{r}
head(xset@phenoData)
```

In this dataset we had 3 groups with 9 samples in each. The first time we do the grouping we are pretty liberal with how often it should be found.

Grouping and retention time correction - minfrac/minsamp
========================================================

<br>

**Consider your experimental design and group VERY carefully when you set these parameters!**

Example:


1. You put all files on one folder.
2. You have 2 study groups with each 20 samples. So 40 samples in total.
3. You set:
  ```{r, eval=FALSE}
  minfrac = 0.7
  minsamp = 30
  ```
4. **You have now removed everything that is unique to one group!** <br>So possibly the most important features have been removed.



Grouping and retention time correction - minfrac/minsamp
========================================================

- LOESS fitting is default
- More  features are not always good
- minsamp/minfrac is per group and critical. phenoData
- bw
- retcor
  - span
- Debugging
  - Peak picking or alignment?
  - bw or mzwid adjustment needed?
  
- Obiwarp as alternative


Filling missing values (fillPeaks)
========================================================
- Importance of profparam previously set
- Problem of very accurate data



Checking the results
========================================================
- Are isomers separated?
- Do you find peaks you know should be there?



Bibliography
========================================================

```{r, echo=FALSE, results="asis"}
bibliography()
```

